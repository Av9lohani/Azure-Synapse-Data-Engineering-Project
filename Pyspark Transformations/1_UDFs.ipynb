{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "mssparkutils.notebook.run('4 - MSSpark Utilities/6 - Mount configuration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## - Accessing the Files from Mountpoint \r\n",
        "## Syntax:\r\n",
        "# synfs:/<jobid>/<mountpoint>/<path>\r\n",
        "# To get JobID - mssparkutils.env.getJobId()\r\n",
        "\r\n",
        "\r\n",
        "job_id = mssparkutils.env.getJobId()\r\n",
        "\r\n",
        "mount_point = 'synfs:/' + job_id + '/lake'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Reading the previous Schema data to a dataframe\r\n",
        "\r\n",
        "df = spark.read.format('parquet')\\\r\n",
        "                .option('header','true')\\\r\n",
        "                .load(mount_point+'/SchemaManagement/*.parquet')\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create normal multiply function in python \r\n",
        "\r\n",
        "def multiply2(x):\r\n",
        "    return x*2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df.createOrReplaceTempView('SchemaView')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.sql(\"SELECT UnEmployed_Rate_Percentage, multiply2(UnEmployed_Rate_Percentage) AS Doubled FROM SchemaView\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Registering the UDF to use in Spark SQL\r\n",
        "\r\n",
        "spark.udf.register('multiply2_udf',multiply2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.sql(\"SELECT UnEmployed_Rate_Percentage, multiply2_udf(UnEmployed_Rate_Percentage) AS Doubled FROM SchemaView\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Applying the registered UDF on dataframe \r\n",
        "\r\n",
        "df.withColumn('multiplied',multiply2_udf(df.UnEmployed_Rate_Percentage)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Registering function to use in Dataframe \r\n",
        "\r\n",
        "from pyspark.sql.functions import udf\r\n",
        "from pyspark.sql.types import DoubleType\r\n",
        "\r\n",
        "multiply2_df_udf = udf(lambda x: multiply2(x), DoubleType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "display(df.withColumn('multiplied',multiply2_df_udf(df.UnEmployed_Rate_Percentage)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Method 2 - Using annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Defining function using annotation \r\n",
        "\r\n",
        "@udf(DoubleType())\r\n",
        "def add3(x):\r\n",
        "    return x+3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "display(df.withColumn('Added',add3(df.UnEmployed_Rate_Percentage)))"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}